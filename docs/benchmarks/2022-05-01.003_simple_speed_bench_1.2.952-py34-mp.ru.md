# Простые тесты скорости работы DedupSQLfs v1.2.952 с разными методами сжатия

Распаковка LibreOffice 6.4.7, 7.1.8, 7.2.7, 7.3.3

Проверка работы на движке: sqlite 3.38.2

CPU: i5-6600K @ 3.50GHz

System: Ubuntu 18.04 amd64

Kernel: 5.4.0-104-lowlatency

Python: 3.4.10

Размер LibreOffice в tar:

* 6.4.7 - 1133M
* 7.1.8 - 1184M
* 7.2.7 - 1204M
* 7.3.3 - 1213M

Другое: включен autocommit, выключен sync, hash=md5, режим=многопроцессный (4x)

Команда:
```sh
/usr/bin/time -v python3.4 ./mount.dedupsqlfs -vv --verbose-stats --data $HOME/Temp/sqlfs/data/ --compress {method} --no-sync --no-cache-flusher --minimal-compress-size -1 --multi-cpu process -o noatime $HOME/Temp/sqlfs/mount
```

Извлечение LO:
```sh
tar xf {libre-tar} -C $HOME/Temp/sqlfs/mount && sudo umount $HOME/Temp/sqlfs/mount
```

Извлечение происходило без стирания предыдущих копий libreoffice. Тестировалась в том числе и дедупликация.

Тестировались только быстрые методы:

* none
* zstd:1
* brotli:0
* zstd:1 + brotli:0

## Тесты

| LO ver   || 6.4.7 ||| 7.1.8 ||| 7.2.7 ||| 7.3.3 ||
|----------|:----:|:----:|:-----:|:----:|:----:|:-----:|:----:|-----:|:-----:|:----:|:----:|:-----:|
| **method** | **time** | **size** | **speed** | **time** | **size** | **speed** | **time** | **size** | **speed** | **time** | **size** | **speed** |
| none     | 1:56.58 | 1095M | 23.91 | 1:54.11 | 1645M | 34.98 | 1:50.34 | 2076M | 37.54 | 1:51.19 | 2477M | 35.75 |
| zstd:1   | 2:02.73 | 422M | 23.45 | 1:54.03 | 612M | 30.07 | 1:51.15 | 749M | 31.84 | 1:50.64 | 873M | 31.68 |
| brotli:0 | 2:03.93 | 450M | 20.14 | 1:54.06 | 657M | 27.86 | 1:50.93 | 806M | 30.96 | 1:51.24 | 942M | 31.04 |
| zstd:1<br>+<br>brotli:0 | 2:03.34 | 422M | 22.12 | 1:58.74 | 612M | 24.70 | 1:51.04 | 749M | 31.06 | 1:52.24 | 873M | 33.16 |

Для сравнения: предыдущие однопоточные
| LO ver   || 6.4.7 ||| 7.1.8 ||| 7.2.7 ||| 7.3.3 ||
|----------|:----:|:----:|:-----:|:----:|:----:|:-----:|:----:|-----:|:-----:|:----:|:----:|:-----:|
| **method** | **time** | **size** | **speed** | **time** | **size** | **speed** | **time** | **size** | **speed** | **time** | **size** | **speed** |
| none     | 1:56.79 | 1095M | 27.98 | 1:59.22 | 1646M | 30.73 | 1:54.59 | 2076M | 40.14 | 1:51.22 | 2477M | 35.29 |
| zstd:1   | 1:58.26 | 420M | 23.95 | 1:53.89 | 609M | 32.20 | 1:50.66 | 746M | 32.24 | 1:51.19 | 869M | 32.10 |
| brotli:0 | 2:03.32 | 448M | 23.01 | 1:58.40 | 654M | 30.37 | 1:52.02 | 804M | 37.62 | 1:54.36 | 939M | 36.82 |
| zstd:1<br>+<br>brotli:0 | 2:06.67 | 420M | 24.75 | 1:56.79 | 609M | 27.77 | 1:55.11 | 746M | 36.55 | 1:53.01 | 870M | 30.54 |

* :time  - время работы dedupsqlfs, в том числе и umount
* :size  - размер итоговых данных в ~/Temp/sqlfs/data/, MiB
* :speed - показатели отладки dedupsqlfs по скорости записи данных, MiB/s

## Результат

Просто посмотреть и сравнить с однопоточным.

- как ни странно, но многопроцессность не сильно помогает
- только если будет использовано много методов сжатия данных
- или если будет выбран высокий уровень сжатия
- возможно, что в python-3.4 медленно работает обмен данными между процессами
